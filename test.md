#Foundation Theory and Motivation
* Hinton, Geoffrey E. “[Deterministic Boltzmann learning performs steepest descent in weight-space](http://www.cs.toronto.edu/~hinton/absps/dbmNC.pdf).” Neural computation 1.1 (1989): 143-150.
* Bengio, Yoshua, and Samy Bengio. “[Modeling high-dimensional discrete data with multi-layer neural networks.](https://www.google.com.hk/url?sa=t&rct=j&q=&esrc=s&source=web&cd=3&ved=0CE8QFjAC&url=%68%74%74%70%3a%2f%2f%63%69%74%65%73%65%65%72%78%2e%69%73%74%2e%70%73%75%2e%65%64%75%2f%76%69%65%77%64%6f%63%2f%64%6f%77%6e%6c%6f%61%64%3f%64%6f%69%3d%31%30%2e%31%2e%31%2e%32%33%2e%38%35%36%38%26%72%65%70%3d%72%65%70%31%26%74%79%70%65%3d%70%64%66&ei=DARuUbvmOo29iAf0pIC4Dg&usg=AFQjCNEb-1lYjNEe-vnZ0ULoX4ScX2eW-g&sig2=MaqdAQRAcdbTc0YrKeOLbA&bvm=bv.45368065,d.aGc&cad=rjt)” Advances in Neural Information Processing Systems 12 (2000): 400-406.
* Bengio, Yoshua, et al. “[Greedy layer-wise training of deep networks.](http://www.stanford.edu/class/psych209a/ReadingsByDate/02_22/BengioEtAl06DBN.pdf)” Advances in neural information processing systems 19 (2007): 153.
* Bengio, Yoshua, Martin Monperrus, and Hugo Larochelle. “[Nonlocal estimation of manifold structure.](http://www.iro.umontreal.ca/~lisa/pointeurs/nc-submission.pdf)” Neural Computation 18.10 (2006): 2509-2528.
* Hinton, Geoffrey E., and Ruslan R. Salakhutdinov. “[Reducing the dimensionality of data with neural networks](http://www.cs.toronto.edu/~hinton/science.pdf).” Science 313.5786 (2006): 504-507.
* Marc’Aurelio Ranzato, Y., Lan Boureau, and Yann LeCun. “[Sparse feature learning for deep belief networks](http://www.cs.nyu.edu/~ranzato/publications/ranzato-nips07.pdf).” Advances in neural information processing systems 20 (2007): 1185-1192.
* Bengio, Yoshua, and Yann LeCun. “[Scaling learning algorithms towards AI](http://yann.lecun.com/exdb/publis/pdf/bengio-lecun-07.pdf).” Large-Scale Kernel Machines 34 (2007).
* Le Roux, Nicolas, and Yoshua Bengio. “[Representational power of restricted boltzmann machines and deep belief networks](http://research.microsoft.com/pubs/64643/representational_power.pdf).” Neural Computation 20.6 (2008): 1631-1649.
* Sutskever, Ilya, and Geoffrey Hinton. “[Temporal-Kernel Recurrent Neural Networks](http://www.cs.utoronto.ca/~ilya/pubs/2008/tkrnn.pdf).” Neural Networks 23.2 (2010): 239-243.
* Le Roux, Nicolas, and Yoshua Bengio. “[Deep belief networks are compact universal approximators](http://snowbird.djvuzone.org/2008/abstracts/160.pdf).” Neural computation 22.8 (2010): 2192-2207.
* Bengio, Yoshua, and Olivier Delalleau. “[On the expressive power of deep architectures](http://www.iro.umontreal.ca/~lisa/pointeurs/ALT2011.pdf).” Algorithmic Learning Theory. Springer Berlin/Heidelberg, 2011.
* Montufar, Guido F., and Jason Morton. “[When Does a Mixture of Products Contain a Product of Mixtures](http://www.personal.psu.edu/gfm10/blogs/gfmc_blog/MontufarTalkISI.pdf).” arXiv preprint arXiv:1206.0387 (2012).
* H. Larochelle, D. Erhan, A. Courville, J. Bergstra, and Y. Bengio. [An Empirical Evaluation of Deep Architectures on Problems with Many Factors of Variation](http://www.cs.toronto.edu/~larocheh/publications/deep-nets-icml-07.pdf). ICML 2007.
* Dumitru Erhan, Yoshua Bengio, Aaron Courville, Pierre-Antoine Manzagol, Pascal Vincent, and Samy Bengio. [Why Does Unsupervised Pre-training Help Deep Learning](http://www.jmlr.org/papers/volume11/erhan10a/erhan10a.pdf) JMLR 2010

#Unsupervised Feature Learning
* Salakhutdinov, Ruslan, and Geoffrey E. Hinton. “[Deep boltzmann machines.](http://www.cs.utoronto.ca/~rsalakhu/papers/dbm.pdf)” Proceedings of the international conference on artificial intelligence and statistics. Vol. 5. No. 2. Cambridge, MA: MIT Press, 2009.
* [Scholarpedia page](http://www.scholarpedia.org/article/Deep_belief_networks) on Deep Belief Networks.
* Ranzato, M'A, Huang, F-J, Boureau, Y-L, and Le Cun, Y.[Unsupervised Learning of Invariant Feature Hierarchies with Applications to Object Recognition](http://yann.lecun.com/exdb/publis/pdf/ranzato-cvpr-07.pdf).CVPR 2007
* Sutskever, I. and Hinton, G. E. [Deep Narrow Sigmoid Belief Networks are Universal Approximators](http://www.cs.toronto.edu/~hinton/absps/universal.pdf).Neural Computation, Vol 20, pp 2629-2636.
* Hinton, G. E.[To recognize shapes, first learn to generate images](http://www.cs.toronto.edu/~hinton/absps/montrealTR.pdf).Technical Report (2006)

###Deep Boltzmann Machines
* [An Efficient Learning Procedure for Deep Boltzmann Machines](http://www.utstat.toronto.edu/~rsalakhu/papers/neco_DBM.pdf), Ruslan Salakhutdinov and Geoffrey Hinton, Neural Computation August 2012, Vol. 24, No. 8: 1967 — 2006.
* Montavon, Grégoire, and Klaus-Robert Müller. “[Deep Boltzmann Machines and the Centering Trick.](http://gregoire.montavon.name/publications/montavon-lncs12.pdf)“ Neural Networks: Tricks of the Trade (2012): 621-637.
* Salakhutdinov, Ruslan, and Hugo Larochelle. “[Efficient learning of deep boltzmann machines.](http://www.mit.edu/~rsalakhu/papers/dbmrec.pdf)“ International Conference on Artificial Intelligence and Statistics. 2010.
* Salakhutdinov, Ruslan. [Learning deep generative models](http://cubs.buffalo.edu/govind/CSE705-SeminarPapers/9.pdf). Diss. University of Toronto, 2009.

###RBMs
* [Tutorial on RBMs](http://deeplearning.net/tutorial/rbm.html)
* [Large-Scale Feature Learning With Spike-and-Slab Sparse Coding](http://icml.cc/2012/papers/718.pdf), Ian Goodfellow, Aaron Courville and Yoshua Bengio, in: ICML’2012
* [Unsupervised Models of Images by Spike-and-Slab RBMs](http://www.iro.umontreal.ca/~lisa/pointeurs/ICML2011_SSRBM.pdf), Aaron Courville, James Bergstra and Yoshua Bengio, in: ICML’2011
* M. Ranzato, A. Krizhevsky, G. Hinton. [Factored 3-Way Restricted Boltzmann Machines for Modeling Natural Images](http://www.cs.toronto.edu/~ranzato/publications/ranzato_aistats2010.pdf). In AISTATS 2010.
* M. Ranzato, G. Hinton, [Modeling Pixel Means and Covariances Using Factorized Third-Order Boltzmann Machines](http://www.cs.toronto.edu/~ranzato/publications/ranzato_cvpr2010.pdf). CVPR 2010
* Dahl, G., Ranzato, M., Mohamed, A. and Hinton, G. E. [Phone Recognition with the Mean-Covariance Restricted Boltzmann Machine](http://www.cs.toronto.edu/~hinton/absps/mcphone.pdf). NIPS 2010

###Autoencoders
* [Regularized Auto-Encoders Estimate Local Statistics](http://arxiv.org/abs/1211.4246), Guillaume Alain, Yoshua Bengio and Salah Rifai, Université de Montréal, arXiv report 1211.4246, 2012
* [A Generative Process for Sampling Contractive Auto-Encoders](http://icml.cc/2012/papers/910.pdf), Salah Rifai, Yoshua Bengio, Yann Dauphin and Pascal Vincent, in: ICML’2012, Edinburgh, Scotland, U.K., 2012
* [Contracting Auto-Encoders: Explicit invariance during feature extraction](http://www.iro.umontreal.ca/~lisa/pointeurs/ICML2011_explicit_invariance.pdf), Salah Rifai, Pascal Vincent, Xavier Muller, Xavier Glorot and Yoshua Bengio, in: ICML’2011
* [Disentangling factors of variation for facial expression recognition](http://www-etud.iro.umontreal.ca/~rifaisal/material/rifai_eccv_2012.pdf), Salah Rifai, Yoshua Bengio, Aaron Courville, Pascal Vincent and Mehdi Mirza, in: ECCV’2012.
* Vincent, Pascal, et al. “[Stacked denoising autoencoders: Learning useful representations in a deep network with a local denoising criterion](http://jmlr.csail.mit.edu/papers/volume11/vincent10a/vincent10a.pdf).“ The Journal of Machine Learning Research 11 (2010): 3371-3408.
* Vincent, Pascal. “[A connection between score matching and denoising autoencoders](http://www.iro.umontreal.ca/~vincentp/Publications/smdae_techreport.pdf).” Neural computation 23.7 (2011): 1661-1674.
* Chen, Minmin, et al. “[Marginalized denoising autoencoders for domain adaptation](http://arxiv.org/pdf/1206.4683).“ arXiv preprint arXiv:1206.4683 (2012).
* Pascal Vincent, Hugo Larochelle, Yoshua Bengio and Pierre-Antoine Manzagol. [Extracting and Composing Robust Features with Denoising Autoencoders](http://www.cs.toronto.edu/~larocheh/publications/icml-2008-denoising-autoencoders.pdf). ICML 2008.
* Notes:They have a nice model, but then backwards rationalize it into a probabilistic model. Ignore the backwards rationalized probabilistic model [Section 4].
